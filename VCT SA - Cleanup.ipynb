{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6ba754-a407-42d9-8454-98a50f97209e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import re\n",
    "import webbrowser\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44318e7a-fa27-416b-837b-69607bcdca2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "day = '2021-12-09'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151c4d15-37be-401b-a227-88d756ac264b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path = f'C:\\\\Users\\\\Ali\\\\Desktop\\\\Coding\\\\Data Science Practice\\\\Twitter\\\\CSV Files\\\\' \n",
    "df_path = f'C:\\\\Users\\\\Ali\\\\Desktop\\\\Coding\\\\Data Science Practice\\\\Twitter\\\\Datasets\\\\' \n",
    "dfalt_path = f'C:\\\\Users\\\\Ali\\\\Desktop\\\\Coding\\\\Data Science Practice\\\\Twitter\\\\Datasets - Alt\\\\' \n",
    "final_path = f'C:\\\\Users\\\\Ali\\\\Desktop\\\\Coding\\\\Data Science Practice\\\\Twitter\\\\Final_Dataset' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5f148e-d786-48b2-91b1-7c0bad84769e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(text):\n",
    "    \n",
    "    # Takes in the list of tweet text and removes any unecessary symbols, numbers, or letters which may interfere with the sentiment analysis\n",
    "    \n",
    "    text = re.sub(r'(@[A-Za-z]+)|([:_]+)', '', text) # remove @ mentions\n",
    "    text = re.sub(r'#', '', text) # remove # symbol\n",
    "    text = re.sub(r'RT[\\s]+', '', text) # remove retweets\n",
    "    text = re.sub(r'https?:\\/\\/\\S+', '', text) # remove hyperlinks\n",
    "    text = re.sub(r'https\\S+', '', text) # remove hyperlinks\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471042be-0c22-4f6f-b205-aaf9aa7f8d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiles all files for each team and creates full datasets for them\n",
    "\n",
    "team = 'sentinels' # Example team: Sentinels\n",
    "df_Tourney = pd.DataFrame()  # Pandas dataframe that will hold all the data\n",
    "for foldername in os.listdir(raw_path): # Finds files\n",
    "    for filename in os.listdir(raw_path+foldername):\n",
    "        if team in filename: # Only chooses files that has the specified team name in its title\n",
    "            df_temp = pd.read_csv(raw_path+foldername+'\\\\'+filename, index_col=0)\n",
    "            df_Tourney = df_Tourney.append(df_temp)\n",
    "            \n",
    "df_Tourney.to_csv(os.path.join(df_path,f'{team} (full).csv')) # Exports the full dataset of a team as a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38690b40-6ae3-4e50-be07-4baff8e5be76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleans all dataset in specified data path\n",
    "\n",
    "for filename in os.listdir(df_path):\n",
    "    if filename.endswith(\".csv\"): \n",
    "        df_temp = pd.read_csv(df_path+'\\\\'+filename, index_col=0)\n",
    "        df_temp = df_temp.drop_duplicates(subset=['url']) # Removes duplicate tweets, based on tweet URL since it's unique to each tweet\n",
    "        df_temp = df_temp.reset_index(drop=True)\n",
    "        df_temp['text'] = df_temp['text'].apply(cleanText)\n",
    "        df_temp['text'] = df_temp['text'].str.replace(r'[^\\x00-\\x7F]+', '', regex=True)\n",
    "        df_temp.to_csv(os.path.join(df_path,filename))\n",
    "        continue\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fc594f-e516-45b0-a936-c305695e390c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final dataset with all tweets\n",
    "\n",
    "df_final = pd.DataFrame()  \n",
    "for filename in os.listdir(df_path):\n",
    "    if filename.endswith(\".csv\"): \n",
    "        df_temp = pd.read_csv(df_path+'\\\\'+filename, index_col=0)\n",
    "        df_final = df_final.append(df_temp)\n",
    "df_final.to_csv(os.path.join(final_path,'VCT Champions Tweets.csv')) # Export to specified folder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
